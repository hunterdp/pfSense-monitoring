filter {

  if [type] == "esxi"  or "lumberjack" in [tags] {
      grok {
        break_on_match => true
        match => [
              "message", "<%{POSINT:syslog_pri}>%{TIMESTAMP_ISO8601:@timestamp} %{SYSLOGHOST:hostname} %{SYSLOGPROG:message_program}: (?<body_type_1>(?<message_body>(?<message_system_info>(?:\[%{DATA:message_thread_id} %{DATA:syslog_level} \'%{DATA:message_service}\'\ ?%{DATA:message_opID}])) \[%{DATA:message_service_info}]\ (?<message_syslog>(%{GREEDYDATA}))))",
              "message", "<%{POSINT:syslog_pri}>%{TIMESTAMP_ISO8601:@timestamp} %{SYSLOGHOST:hostname} %{SYSLOGPROG:message_program}: (?<body_type_2>(?<message_body>(?<message_system_info>(?:\[%{DATA:message_thread_id} %{DATA:syslog_level} \'%{DATA:message_service}\'\ ?%{DATA:message_opID}])) (?<message_syslog>(%{GREEDYDATA}))))",
              "message", "<%{POSINT:syslog_pri}>%{TIMESTAMP_ISO8601:@timestamp} %{SYSLOGHOST:hostname} %{SYSLOGPROG:message_program}: (?<body_type_3>(?<message_body>%{GREEDYDATA:message_syslog}))",
              "message", "<%{POSINT:syslog_pri}>.*?[\s\r\t](?<hostname>[a-zA-Z0-9\-_]+[.][a-zA-Z0-9\-_\.]+)[\s].*?(?<message_program>[a-zA-Z0-9\-\[\]_]{3,})[:][\s](?<body_type_6>(?<message_body>(?<message_syslog>.*)))",
              "message", "(?<body_type_7>(?<message_body>(?<message_debug>.*)))"
        ]
      }

    if [message] =~ /(?i)warning|error|fault|ALERT|busy|Failed|[\s]dead|[\s]space|esx\.|vob\.|com\.vmware|nmp|volume|consolidate|FS3|question|ha-eventmgr|VisorFS|Fil3|DLX|MCE|HBX|MPN|mpn|p2m|Reset|timeout|msg\./ and [message] !~ /(?i)crossdup|hostprofiletrace/{
    
      if [message] =~ /(?i)vmkwarning:/ and [message] !~ /(?i)crossdup|performance|LinuxCharWrite/{
      # <181>2014-12-18T18:30:36.400Z esx.vmware.com vmkwarning: cpu29:4317)WARNING: vmw_psp_rr: psp_rrSelectPathToActivate:972:Could not select path for device "naa.60002ac000000000000004b00000d155".
        mutate {
          add_tag =>  "vmkwarning"
        }
      }

      if [message] =~ /(?i)ALERT:/{
      # <181>2014-12-17T07:50:52.629Z esx.vmware.com vmkernel: cpu9:8942)ALERT: URB timed out - USB device may not respond
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "ALERT" }
        }
      } else if [message] =~ /(?i)[\s]dead/ {
      # <166>2014-09-15T14:52:23.782Z esx.vmware.com Hostd: [77381B90 error 'Default'] Unable to build Durable Name dependent properties: Unable to query VPD pages from device, all paths are dead, no I/O possible.
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "dead" }
        }
      } else if [message] =~ /(?i)[\s]space/ and [message] !~ /(?i)Need/{
      # <181>2014-12-10T15:19:40.411Z esx.vmware.com vmkernel: cpu6:16764680)WARNING: Swap: vm 17473281: 5501: Failed to extend swap file type=regular from 0 KB to 4194304 KB. status=No space left on device
      # <166>2014-12-10T15:54:45.807Z esx.vmware.com Hostd: [55124B90 info 'ha-eventmgr'] Event 3593 : Message on vm_name on esx.vmware.com in ha-datacenter: There is no more space for virtual disk /vmfs/volumes/512f4eb6-27ff1a2e-f082-d4ae5264813c/vm_name/vm_name.vmdk. You might be able to continue this session by freeing disk space on the relevant volume, and clicking Retry. Click Cancel to terminate this session.
      # <13>2014-12-22T01:01:01Z esx.vmware.com root: Unable to extract system configuration.  Are you out of disk space?
      
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "space" }
        }
      } else if [message] =~ /(?i)esx\.problem/ {
      # <14>2014-12-10T18:01:03.496Z esx.vmware.com vobd:  [scsiCorrelator] 14807183227307us: [esx.problem.scsi.device.io.latency.high] Device naa.60a9800041764b6c463f437868556b7a performance has deteriorated. I/O latency increased from average value of 1343 microseconds to 28022 microseconds.
        grok {
          match => [
            "message", "(?<esx_problem>esx\.problem\.[a-zA-Z\.]+)"
          ]
          add_tag =>  "alert"
          add_field => { "alert" => "%{esx_problem}" }
        }
        if [message] =~ /(?i)lost|degraded|ntpd|pageretire|apd|permanentloss|atquota|pathstatechanges|visorfs|heartbeat|corrupt|disconnect|scsipath\.por|dump|duplicate/ {
          mutate {
            add_tag =>  "achtung"
          }
        }        
      } else if [message] =~ /(?i)esx\.clear/ {
      # <14>2014-12-10T16:31:21.405Z esx.vmware.com vobd:  [UserLevelCorrelator] 84941123us: [esx.clear.coredump.configured] A vmkcore disk partition is available and/or a network coredump server has been configured.  Host core dumps will be saved.
        grok {
          match => [
            "message", "(?<esx_clear>esx\.clear\.[a-zA-Z\.]+)"
          ]
          add_tag =>  "alert"
          add_field => { "alert" => "%{esx_clear}" }
        }
      } else if [message] =~ /(?i)esx\.audit/ {
      # <14>2014-12-10T16:31:21.337Z esx.vmware.com vobd:  [UserLevelCorrelator] 84872345us: [esx.audit.host.boot] Host has booted.
        grok {
          match => [
            "message", "(?<esx_audit>esx\.audit\.[a-zA-Z\.]+)"
          ]
          add_tag =>  "alert"
          add_field => { "alert" => "%{esx_audit}" }
        }
      } else   if [message] =~ /(?i)vob\./ {
      # <14>2014-12-10T17:28:18.087Z esx.vmware.com vobd:  [GenericCorrelator] 3639187707810us: [vob.user.iorm.nonviworkload] Detected a non vi workload on datastore datastore_name
        grok {
          match => [
            "message", "(?<vob>vob\.[a-zA-Z\.]+)"
          ]
          add_tag =>  "alert"
          add_field => { "alert" => "%{vob}" }
        }
        if [message] =~ /(?i)dead|corruptondisk|mce|dump|heartbeat/ {
          mutate {
            # add_tag =>  "achtung"
          }
        }          
      } else   if [message] =~ /(?i)com\.vmware/ {
      # <181>2014-12-10T17:14:26.203Z esx.vmware.com vmkernel: cpu10:674239)DVSDev: DVSDevDataSet:968: setting data com.vmware.common.port.volatile.persist on port 2675
        grok {
          match => [
            "message", "(?<com_vmware>com\.vmware\.[a-zA-Z\.]+)"
          ]
          add_field => { "alert" => "%{com_vmware}" }
        }
        if [message] =~ /(?i)com\.vmware\.vc\.ha\./ {
          mutate {
            add_tag =>  "achtung"
          }
        }
      } else if [message] =~ /(?i)nmp/ {
      # <181>2014-12-10T18:21:53.018Z esx.vmware.com vmkernel: cpu13:1264143)WARNING: NMP: nmp_DeviceRequestFastDeviceProbe:237:NMP device "naa.60a9800041764b6c463f437868556c47" state in doubt; requested fast path state update...
        grok {
          match => [
            "message", "(?<nmp>nmp_[a-zA-Z0-9\-_]+)[:]"
          ]
          add_tag =>  "alert"
          add_field => { "alert" => "%{nmp}" }
        }
      } else if [message] =~ /(?i)Lost access to volume/ {
      # <166>2014-12-16T22:07:35.612Z esx.vmware.com Hostd: [3647FB90 info 'ha-eventmgr'] Event 89814 : Lost access to volume 50867547-26003ed2-06b9-0024e8565b3d (datastore_name) due to connectivity issues. Recovery attempt is in progress and outcome will be reported shortly.
        grok {
          match => [
            "message", "(?i)Lost access to volume.*(%{GREEDYDATA:lost_datastore})"
          ]
          add_tag =>  "achtung"
          add_field => { "alert" => "Lost access to volume" }
        }
      } else if [message] =~ /(?i)Long VMFS3 rsv time/{
      # <181>2014-12-10T18:59:00.309Z esx.vmware.com vmkernel: cpu45:9821)FS3Misc: 1440: Long VMFS3 rsv time on 'datastore_name' (held for 261 msecs). # R: 1, # W: 1 bytesXfer: 5 sectors
          grok {
            match => [
              "message", "Long VMFS3 rsv time on '%{GREEDYDATA:datastore_name}'"
            ]
            add_field => { "alert" => "Long_VMFS3_rsv_time" }
          }
      } else if [message] =~ /(?i)question/ and [message] !~ /(?i)Answered/{
      # <166>2014-12-17T13:37:14.310Z esx.vmware.com Hostd: [34DD1B90 verbose 'vm:/vmfs/volumes/5335bc2e-70db5326-9cc7-f0921c0b59bd/vm_name/vmx_name.vmx'] Clearing VM question
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "question_not_answered" }
        }
      } else if [message] =~ /(?i)ha-datacenter/ and [message] =~ /ha-eventmgr/{
        grok {
          match => [
            "message", ".*ha-eventmgr.*(M|m)essage.*ha-datacenter:[\s]{0,1}%{DATA:ha_datacenter_msg}"
          ]
        }
      } else if [message] =~ /(?i)visorfs/ and [message] =~ /(?i)inode/ and [message] !~ /(?i)hostprofiletrace/ {
      #<181>2014-12-10T16:09:58.394Z esx.vmware.com vmkernel: cpu29:5640)VisorFS: 688: Failed to get object 4 inode 7921234 :Transient file system condition, suggest retry
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "visorfs" }
        }
      } else if [message] =~ /(?i)Fil3:/{
      # <181>2014-12-08T21:10:25.383Z esx.vmware.com vmkernel: cpu9:5007)Fil3: 13496: Max retries (10) exceeded for caller Fil3_FileIO (status 'IO was aborted by VMFS via a virt-reset on the device')
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "Fil3" }
        }
        if [message] =~ /(?i)virt\-reset/{
          mutate {
            add_field => { "alert" => "virt-reset" }
          }
        }
      } else if [message] =~ /(?i)busy/ and [message] !~ /(?i)crossdup|hostprofiletrace/{
      # <14>2014-12-18T17:15:55.901Z esx.vmware.com storageRM:  <datastore_name>  retry : 1,  Device or resource busy Error -1 opening file /vmfs/volumes//datastore_name/.iorm.sf/slotsfile
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "busy" }
        }              
      } else if [message] =~ /(?i)DLX:/{
      # <181>2014-12-19T07:28:11.537Z esx.vmware.com vmkernel: cpu22:4167)DLX: 3394: vol 'datastore_name': [Req mode 1] Checking liveness of [type 10c00002 offset 9684992 v 204, hb offset 3223552
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "DLX" }
        }
      } else if [message] =~ /(?i)FS3:/ and [message] !~ /(?i)Long VMFS3 rsv time/{
      # <181>2014-12-17T03:14:41.217Z esx.vmware.com vmkernel: cpu13:13040893)FS3: 1341: vol 'datastore_name': [Req mode: 1] Not free; Lock [type 10c00002 offset 11296768 v 274, hb offset 3719168
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "FS3" }
        }
      } else if [message] =~ /(?i)Failed to lock/{
      # <166>2014-12-10T17:36:09.120Z esx.vmware.com Vpxa: [FFF08B90 info 'DiskLib' opID=36139059-8e] DISKLIB-DSCPTR: DescriptorDetermineType: failed to open '/vmfs/volumes/5335bc2e-70db5326-9cc7-f0921c0b59bd/vm_name/vm_name-flat.vmdk': Failed to lock the file (400000003)
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "failed_to_lock" }
        }
      } else if [message] =~ /(?i)FileIO error/{
      # <166>2014-12-10T13:05:07.765Z esx.vmware.com Hostd: [FF9EFAD0 error 'Statssvc'] Unable to load stats depot hostAgentStats in directory /var/lib/vmware/hostd/stats/ : FileIO error: Could not find file  : /var/lib/vmware/hostd/stats/hostAgentStats.idMap
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "FileIO_error" }
        }
      } else if [message] =~ /(?i)Device or resource busy/{
      # <14>2014-12-19T09:50:55.992Z esx.vmware.com storageRM:  open /vmfs/volumes//datastore_name/.iorm.sf/slotsfile(0x10000042, 0x0) failed: Device or resource busy
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Device_or_resource_busy" }
        }
      } else if [message] =~ /(?i)MCE:/{
      # <181>2014-12-19T13:43:04.147Z esx.vmware.com vmkernel: cpu0:9892203)MCE: 1282: Status bits: "Memory Controller Error."
        mutate {
          # add_tag =>  "alert"
          add_field => { "alert" => "Machine_Check_Exception" }
        }
      } else if [message] =~ /(?i)failed to open/ and [message] !~ /(?i)Failed to lock/{
      # <166>2014-12-10T13:27:10.622Z esx.vmware.com Vpxa: [4D343B90 warning 'Libs' opID=feab74be-b8] [NFC ERROR] NfcFile_GetInfo: Failed to open file
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "failed_to_open" }
        }
      } else if [message] =~ /(?i)The file specified is not a virtual disk/{
      # <166>2014-12-10T14:13:35.458Z esx.vmware.com Vpxa: [FFEE7B90 info 'DiskLib' opID=bb64bb70-90] DISKLIB-LINK  : "/vmfs/volumes/5417e43a-a20f2412-f4b1-f0921c0b59bd/vm_name/vm_name-flat.vmdk" : failed to open (The file specified is not a virtual disk).
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "not_a_virtual_disk" }
        }
      } else if [message] =~ /(?i)Failed to load virtual machine/{
      # <166>2014-10-01T08:35:11.001Z esx.vmware.com Hostd: [FF8A5AD0 info 'vm:/vmfs/volumes/53a2afe2-799847f0-5f86-d89d675b0341/PARG1DFXOFXC03/PARG1DFXOFXC03.vmx'] Failed to load virtual machine. Marking as unavailable: vim.fault.InvalidVmConfig
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "InvalidVmConfig" }
        }        
      } else if [message] =~ /(?i)HBX:/{
      # <181>2014-12-08T21:10:11.803Z esx.vmware.com vmkernel: cpu12:4131)HBX: 231: Reclaimed heartbeat for volume 50813de9-d9039ea0-d6c1-0024e8565b3d (datastore_name): [Timeout] [HB state abcdef02 offset 3829760 gen 55 stampUS 20086651705675 uuid 5353935d-484cdab2-a7e9-0017a477$
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "HBX" }
        }
      } else if [message] =~ /(?i)[\s](mpn)[s]{0,1}[\s]/{
      # <181>2014-12-10T11:13:09.089Z esx.vmware.com vmkernel: cpu32:115278)PageRetire: 1237: Invalid MPN range [0x0, 0x1)
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Machine_Page_Number" }
        }
      } else if [message] =~ /(?i)Input\/output error/{
      # <166>2014-12-19T11:03:46.984Z esx.vmware.com Hostd: -->  Error : Error: Error opening /dev/disks/naa.50060160bb20559c50060160bb20559c: Input/output error
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Input_output_error" }
        }
      } else if [message] =~ /(?i)Could not open device/{
      # <182>2014-08-12T15:54:49.908Z esx.vmware.com vmkernel: cpu26:13028837)Vol3: 2174: Could not open device 'naa.600605b0070ec9c01b0613ea1266322e:5' for probing: I/O error
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "Could_not_open_device" }
        }
      } else if [message] =~ /(?i)cannot reserve/{
      # <181>2014-12-10T19:17:17.845Z esx.vmware.com vmkernel: cpu3:9223998)VmMemCow: 1599: p2m update: cannot reserve - cur 2432 2432 rsvd 0 req 1 avail 2432
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "cannot_reserve" }
        }
      } else if [message] =~ /(?i)Failed to delete/{
      # <166>2014-12-16T07:51:54.614Z esx.vmware.com Hostd: [213E0B90 warning 'vm:/vmfs/volumes/4cd43053-eed404ad-27c4-78e7d163b271/vm_name/vmx_name.vmx' opID=662EDE05-00008331-5c-62] DeleteVmDirectory: Failed to delete vm dir '/vmfs/volumes/4cd43053-eed404ad-27c4-78e7d163b271/vm_name'
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Failed_to_delete" }
        }
      } else if [message] =~ /(?i)A fault has occurred causing a virtual CPU to enter the shutdown state/{
          mutate {
            add_tag =>  "alert"
            add_field => { "alert" => "vcpu_shutdown_state" }
          }
      } else if [message] =~ /(?i)The system has rolled back to a previous image/{
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "The_system_has_rolled_back" }
        }
      } else if [message] =~ /(?i)more than 100 redo logs/{
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "more_than_100_redo_logs" }
        }
      } else if [message] =~ /(?i)Failed to consolidate/{
      # <166>2014-12-29T09:47:08.482Z esx.vmware.com Hostd: [32FFFB90 info 'vm:/vmfs/volumes/54929abf-956ed001-31e1-d89d675ba101/vm_name/vmx_name.vmx'] Failed to consolidate disks in Foundry: Error: (15) The file is already in use
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Failed_to_consolidate" }
        }
      } else if [message] =~ /(?i)needConsolidate is true/{
      # 2012-05-22T12:36:59.101Z [5ED40B90 verbose 'vm:/vmfs/volumes/4f66bf0c-9c44e66e-d073-984be10fb0db/vm_name/vmx_name.vmx'] Time to gather Snapshot information ( read from disk, build tree): 3 msecs. needConsolidate is true.
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "needConsolidate" }
        }
      } else if [message] =~ /(?i)ErrDev/{
        # <181>2014-12-10T10:58:18.738Z esx.vmware.com vmkwarning: cpu12:12414801)WARNING: ErrDev: 94: The err device was accessed.  This should not happen frequently.
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "The_err_device_was_accessed" }
        }
      } else if [message] =~ /(?i)vmodl.fault.ManagedObjectNotFound/{
        # 2015-01-15T17:48:31.426Z [21B61B90 verbose 'Placement' opID=SWI-7a6e2ab8] [PlacementManagerImpl::HandleNotPlacedVms] Reset Vm /vmfs/volumes/4ea98080-426bf6f3-0aaf-78e7d163b271/vm_name/vmx_name.vmx, vmodl.fault.ManagedObjectNotFound
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "vmodl.fault.ManagedObjectNotFound" }
        }
      } else if [message] =~ /(?i)msg\.[a-zA-Z0-9\-_\.]+/ {
        # <166>2015-01-22T22:31:58.616Z esx.vmware.com vmkwarning Hostd: -->          key = "msg.checkpoint.precopyfailure",
        grok {
          match => [
            "message", "(?<msg>msg\.[a-zA-Z0-9\-_\.]+)"
          ]    
        }
        if [msg] != "msg.dictionary.load.openFailed|msg.mks.failedResolutionSet" {
          mutate {
            add_field => { "alert" => "%{msg}" }          
            add_tag =>  "achtung"
          }
        }        
      } else if [message_program] =~ /(?i)PLOGDefenceProbeInterval/{
        # <182>2015-06-21T00:12:21.836Z esx.vmware.com vmkernel: cpu33:32801)WARNING: PLOG: PLOGDefenceProbeInterval:5363: Throttled: PROBE_INTERVAL should > IO timeout. Using IO timeout value for probe interval.
        mutate {
          add_field => { "alert" => "PLOGDefenceProbeInterval" }
        }
      } else if [message] =~ /(?i)can't alloc event metadata/{
        # <180>2015-06-21T00:11:51.617Z esx.vmware.com vmkwarning: cpu21:33459)WARNING: Unable to deliver event to user-space - can't alloc event metadata
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "cant_alloc_event_metadata" }
        }
      } else if [message] =~ /(?i)Unable to register file system/{
        # <182>2015-06-21T00:05:50.646Z esx.vmware.com vmkernel: cpu33:35056)Vol3: 950: Unable to register file system 4b6b8155-cd9c-91af-9a96-44a842145c12 for APD timeout notifications: Inappropriate ioctl for device
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "Unable_to_register_file_system" }
        }
      } else if [message] =~ /(?i)Can't find datastore/{
        # <164>NoneZ esx.vmware.com Hostd: 2015-06-21T00:02:08.553Z warning hostd[49580B70] [Originator@6876 sub=Hostsvc.VmkVprobSource] Can't find datastore 'e4e75455-1a38-ca0e-bfae-44a842145c12'.
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "Cant_find_datastore" }
        }
      } else if [message] =~ /(?i)VsanSparseWarnUnsupportedIoctl/{
        # <180>2015-06-27T10:50:37.058Z esx.vmware.com vmkwarning: cpu0:33140)WARNING: VSAN: VsanSparseWarnUnsupportedIoctl:3795: Throttled: VsanSparse does not support FDS_IOCTL_RESET_COMMAND 'FDS reset command ioctl' (0xd), disk a160460-aa648e55-76ed-4d2c-8b5d-44a842145c12
        mutate {
          add_field => { "alert" => "VsanSparseWarnUnsupportedIoctl" }
        }
      } else if [message] =~ /(?i)recoveryETA/{
        # <13>2015-06-27T11:30:06Z esx.vmware.com clomd[33803]: Sync" l0) ("recoveryETA" i0) ("faultDomainId" 55494b93-2bec-840a-54b8-44a842147fac) ("flags" i0) ("nVotes" i0)) bd5d8755-2865-2654-7783-44a842145c12 5212501e-8f31-d27c-2754-3577b4cd7fcd))))
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "recoveryETA" }
        }
      } else if [message] =~ /(?i)Rebalance/{
        # <13>2015-06-27T11:30:41Z PRD-ESX-04.adm clomd[33806]: CLOMBalance_CopyMoveListToWorkItem: Rebalance component 02fe8655-c53a-a387-5b97-44a842147fac of object 02fe8655-db88-e355-64ac-44a842147fac to 52d3f4a2-0cc1-b43e-1bf1-7d4d3bf5f001
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "Rebalance" }
        }
      } else if [message] =~ /(?i)Trying to liberate/{
        # <13>2015-06-27T14:33:01Z PRD-ESX-03.adm clomd[33804]: CLOMBalance_RebalanceDisk: Trying to liberate 126831858249 bytes from disk 5299e143-070f-22d6-836f-fca7d91952c4 (Cap:990191288320 Used:990191288320) in normal mode
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "Trying_to_liberate" }
        }
      } else if [message] =~ /(?i)rebalanceInProgress/{
        # <12>2015-06-27T11:32:03Z PRD-ESX-03.adm clomd[33804]: Setting rebalanceInProgress to TRUE
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "rebalanceInProgress" }
        }
      } else if [message] =~ /(?i)CLOMRebalanceObject/{
        # <13>2015-06-27T11:32:03Z PRD-ESX-03.adm clomd[33804]: CLOMRebalanceObject: Marked components successfully
        mutate {
          add_tag =>  "achtung"
          add_field => { "alert" => "CLOMRebalanceObject" }
        }
      }
      

    #################    


    #    if [message] =~ /Can't convert IP Address of type 0/{
    #      mutate {
    #        add_tag =>  "alert"
    #        add_field => { "alert" => "IP_Address_type_0" }
    #      }
    #    }
        
    #    if [message] =~ /vim.fault.InvalidState/{
        # <166>2014-12-10T15:32:50.535Z esx.vmware.com Hostd: [2C3ECB90 info 'Default' opID=b380000c-8a] AdapterServer caught exception: vim.fault.InvalidState
    #      mutate {
    #        add_tag =>  "alert"
    #        add_field => { "alert" => "vim.fault.InvalidState" }
    #      }
    #    }
        
    #    if [message] =~ /Failed to diff/{
        # <166>2014-12-10T13:05:58.790Z esx.vmware.com Vpxa: [FFFBAB90 error 'PropertyCache' opID=WFU-9c45a380] Failed to diff ha-host:network, had ManagedObjectReference[], got ManagedObjectReference[]
    #      mutate {
    #        add_tag =>  "alert"
    #        add_field => { "alert" => "Failed_to_diff" }
    #      }
    #    }
        
    #    if [message] =~ /Failed write command to write-quiesced partition/{
        # ALERT: ScsiDeviceIO: 3075: Failed write command to write-quiesced partition naa.6006000000000000aa0aaa0000a0a000:1
    #      mutate {
    #        add_tag =>  "achtung"
    #        add_field => { "alert" => "Failed_write_command" }
    #      }
    #    }
        
    #    if [message] =~ /No such file or directory/ and [message] !~ /load.openFailed/{
    #    # <166>2014-12-10T16:49:03.570Z esx.vmware.com Hostd: [379D2B90 verbose 'vm:/vmfs/volumes/548076ca-1a5e9feb-b886-fc15b415a120/vm_name/vmx_name.vmx'] UpdateFileInfo: Failed to find file size for : No such file or directory
    #      mutate {
    #        # add_tag =>  "alert"
    #        add_field => { "alert" => "No_such_file_or_directory" }
    #      }
    #    }
        
    #    if [message] =~ /poweron failed with Input\/output error /{
    #      mutate {
    #        add_tag =>  "alert"
    #        add_field => { "alert" => "poweron_failed" }
    #      }
    #    }

    #    if [message] =~ /L2Sec_EnforcePortCompliance/{
      # <181>2014-12-10T19:23:45.733Z esx.vmware.com vmkernel: cpu14:1559738)etherswitch: L2Sec_EnforcePortCompliance:226: client vm_name.eth0 requested promiscuous mode on port 0x200002b, disallowed by vswitch policy 
    #    mutate {
    #      add_tag =>  "alert"
    #      add_field => { "alert" => "L2Sec_EnforcePortCompliance" }
    #    }
    #  }

    }
  
    #################

    if [message] =~ /(?i)vmfs/ {
    # <166>2014-12-10T18:33:54.239Z esx.vmware.com Hostd: [3451AB90 verbose 'vm:/vmfs/volumes/f8431d5d-1d30ae43/vm_name/vmx_name.vmx'] Actual VM overhead: 170840064 bytes
      grok {
        match => [
          "message", "/vmfs/volumes/%{USERNAME:vmfs_uuid}/%{USERNAME:vm_name}/%{USERNAME:vmx_name}[.](vmx|vswp|vmdk|log|vmxf|ctk|vmss|nvram|xml)",
          "message", "/vmfs/volumes/%{USERNAME:vmfs_uuid}"
        ]
      }
    }

    if [message] =~ /(?i)naa\./ {
    # <181>2014-12-10T18:25:25.426Z esx.vmware.com vmkernel: cpu9:7045276)ScsiDeviceIO: 1198: Device naa.60a9800041764b6c463f437868556b7a performance has improved. I/O latency reduced from 5587 microseconds to 2650 microseconds.
      grok {
        match => [
          "message", "(?<canonical_name>naa\.[a-f0-9]+)"
        ]
      }
    }

    if [message] =~ /(?i)MB/ {
    # <181>2014-12-10T18:50:27.101Z esx.vmware.com vmkernel: cpu11:1674338)VMotionSend: 3508: 1418237421145920 S: Sent all modified pages to destination (network bandwidth ~460.523 MB/s)
      grok {
        match => [
          "message", "[~\s]{0,1}%{NUMBER:mbps:float}[\s]{0,1}MB\/s"
        ]
      }
    }

    if [message] =~ /(?i)ms/ {
    # <181>2014-12-10T18:43:57.374Z esx.vmware.com vmkernel: cpu3:9751)FS3Misc: 1440: Long VMFS3 rsv time on 'datastore_name' (held for 272 msecs). # R: 1, # W: 1 bytesXfer: 5 sectors
      grok {
        match => [
          "message", "[\s]%{NUMBER:milliseconds:int}[\s].*(ms|msecs)"
        ]
      }
    } else if [message] =~ /(?i)micro/ {
      grok {
        match => [
          "message", ".*[\s]%{NUMBER:microseconds:int}[\s]micro[sS]ec"
        ]
      }
    }

    if [message] =~ /(?i)vmhba/ {
    # <181>2014-12-10T16:30:49.589Z esx.vmware.com vmkernel: cpu14:4739)ScsiPath: 4552: Plugin 'NMP' claimed path 'vmhba0:C0:T0:L3'
      grok {
        match => [
          "message", "(?<runtime_name>vmhba[0-9]+:C[0-9]+:T[0-9]+:L[0-9]+)"
        ]
      }
    }

    if [message] =~ /(?i)sense data/ {
    # <181>2014-12-10T18:21:53.018Z esx.vmware.com vmkernel: cpu13:1264143)ScsiDeviceIO: 2311: Cmd(0x4124403de140) 0x28, CmdSN 0x8000004b from world 1171425 to dev "naa.60a9800041764b6c463f437868556c47" failed H:0x2 D:0x0 P:0x0 Possible sense data: 0x0 0x0 0x0.
      grok {
        match => [
          "message", "(?<scsi_code>H:[a-f0-9]+x[a-f0-9]+ D:[a-f0-9]+x[a-f0-9]+ P:[a-f0-9]+x[a-f0-9]+).*(?<sense_data>[a-f0-9]+x[a-f0-9]+ [a-f0-9]+x[a-f0-9]+ [a-f0-9]+x[a-f0-9]+)"
        ]
      }
      if [sense_data] != "0x0 0x0 0x0" {
        mutate {
          add_tag =>  "alert"
          add_field => { "alert" => "%{sense_data}" }
        }
      }
    }
    
    if [message] =~ /(?i)vmnic/ {
    # <181>2014-12-10T18:44:52.380Z esx.vmware.com vmkernel: cpu18:8243)<3>ixgbe: vmnic6: ixgbe_alloc_rx_queue: allocated rx queue 1
      grok {
        match => [
          "message", "(?<vmnic>vmnic[0-9]+)"
        ]
      }
    }
    
    if [message] =~ /(?i)[\s]vol[\s]/{
    # <181>2014-12-18T00:48:42.879Z esx.vmware.com vmkernel: cpu5:14780898)FS3: 1227: vol 'datastore_name': [Req mode: 1] Checking liveness of [type 10c00002 offset 9834496 v 1112, hb offset 3719168
        grok {
          match => [
            "message", " vol '%{GREEDYDATA:datastore_name}'"
          ]
        }
    }

    if [message] =~ /(?i)vim\./ {
    # <166>2014-12-10T18:39:25.632Z esx.vmware.com Vpxa: [FFBAAB90 verbose 'Default' opID=SWI-88e6d2f0] [TaskInfoChannel::GetTaskInfo] task: haTask--vim.host.VMotionManager.initiateDestination-134036228 setup for async notification
      grok {
        match => [
          "message", "(?<vim>vim\.[a-zA-Z\.]+)"
        ]
      }
    }

    if [message] =~ /(?i)vmodl\./ {
    # <166>2014-12-10T18:42:14.963Z esx.vmware.com Hostd: [25D95B90 info 'Vmomi'] Throw vmodl.fault.RequestCanceled
      grok {
        match => [
          "message", "(?<vmodl>vmodl\.[a-zA-Z\.]+)"
        ]
      }
    }

    if [message] =~ /(?i)Correlator/ {
    # <14>2014-12-10T16:31:09.619Z esx.vmware.com vobd:  [netCorrelator] 73154456us: [esx.audit.net.firewall.config.changed] Firewall configuration has changed. Operation 'add' for rule set webAccess succeeded.
      grok {
        match => [
          "message", "\[(?<Correlator>.*Correlator)\]"
        ]
      }
    }
    
    if [message] =~ /(?i)vmotion/ {
    # <166>2014-12-10T18:28:11.769Z esx.vmware.com Vpxa: [FFF69B90 verbose 'Default' opID=task-internal-1-19c63550-66-6-e2-56-d2-77-90-e5] [MIGRATE] (1418236087721814) vmotion result has downtime value 284157
      grok {
        match => [
          "message", "vmotion result has downtime value %{NUMBER:vmotion_downtime:int}"
        ]
      }
    }
    
    if [message] =~ /(?i)precopyStunTime/ {
    # <166>2014-12-10T18:33:19.874Z esx.vmware.com Hostd: [6A623B90 verbose 'VMotionSrc (1418236393436303)'] Set source task result precopyStunTime to 68427
      grok {
        match => [
          "message", "precopyStunTime to %{NUMBER:precopyStunTime:int}"
        ]
      }
    }
    
    if [message] =~ /(?i)failed[\s]to[\s]/ {
    # <166>2015-01-05T16:34:54.973Z esx.vmware.com Hostd: [692A5B90 warning 'vm:/vmfs/volumes/c12f0795-0b6af776/vm_name/vmx_name.vmx' opID=HB-host-9145@3421082-b1b1241a-f9] Failed to unregister: vim.fault.TaskInProgress
      grok {
        match => [
          "message", "(?i).*(?<failed_to>failed to [a-zA-Z ]+)"
        ]
        add_tag =>  "failed_to"
      }
    }    
    
    #################

    if [message_program] == "storageRM" {
      # <14>2014-12-10T18:33:04.910Z esx.vmware.com storageRM:  <datastore_name> 2707630 avglatency= 0.83 iops= 84 threshold= 30 Win = 30.00 ws= 30 devqdepth= 30 iocount= 4 noio= 0.00 coio= 0.05
        grok {
          match => [
              "message", "storageRM:[\s]+<%{GREEDYDATA:iorm_datastore}>.*avglatency=[\s]+%{NUMBER:iorm_avglatency:float}[\s]+iops=[\s]+%{NUMBER:iorm_iops:int}.*devqdepth=[\s]+%{NUMBER:iorm_devqdepth:int}"
              ]
          add_tag =>  "iorm"  
        }
        mutate {
          gsub => [
          "iorm_datastore", ", 0", ""
          ]
        }
    }

    
    # date {
    #   match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    # }

    syslog_pri { }
  }
  
}
